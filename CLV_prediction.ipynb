{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4c7adb8b",
      "metadata": {
        "id": "4c7adb8b"
      },
      "source": [
        "# Predict customer lifetime values of e-commerce customers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c514e2d",
      "metadata": {
        "id": "5c514e2d"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Customer Lifetime Value (CLV) is an essential exercise for e-commerce businesses aiming to evaluate the total revenue a company can expect from a single customer account. My project aims to construct a predictive model for CLV that encapsulates and forecasts the net profit attributed to the entire prospective relationship with customers. Such a model is vital for optimizing marketing strategies, focusing on customer retention, and effectively allocating resources towards the most promising customer segments."
      ],
      "metadata": {
        "id": "HFkf7p2nqSdi"
      },
      "id": "HFkf7p2nqSdi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "M-AbohVrgxh7"
      },
      "id": "M-AbohVrgxh7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a dataset from the UCI Machine Learning Repository with detailed transaction records from a UK-based online retailer from December 2009 to December 2011."
      ],
      "metadata": {
        "id": "yPKU_ThAg-SM"
      },
      "id": "yPKU_ThAg-SM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df395cac",
      "metadata": {
        "id": "df395cac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "dt = pd.read_excel('sample_online_ec.xlsx', engine='openpyxl')\n",
        "dt.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83817ec5",
      "metadata": {
        "id": "83817ec5"
      },
      "outputs": [],
      "source": [
        "# remove rows without description, replace missing customer ID with placeholders, and save them to the new csv file.\n",
        "dt_clean = dt.dropna(subset=['Description'])\n",
        "dt_clean = dt.dropna(subset=['Customer ID'])\n",
        "dt_clean.to_csv('dt_clean.csv', index=False)\n",
        "dt_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acc5dab6",
      "metadata": {
        "id": "acc5dab6"
      },
      "source": [
        "## Data Understanding - Univariate Analysis of Quantitative Features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 'Quantity' data"
      ],
      "metadata": {
        "id": "xZGrA3tijczn"
      },
      "id": "xZGrA3tijczn"
    },
    {
      "cell_type": "markdown",
      "id": "4c3c2965",
      "metadata": {
        "id": "4c3c2965"
      },
      "source": [
        "From the histogram, we can observe the most frequent quantity of items purchased in transactions falls between 0 and 10, with a notable peak at around 4 items per purchase. This central tendency is confirmed by the summary statistics and the median ('50%') value in the provided data snippet, which indicates a median purchase quantity of 4 items.\n",
        "\n",
        "Interestingly, there are negative quantities which could indicate returned items, other adjustments to orders, or data entry error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "991b169f",
      "metadata": {
        "scrolled": false,
        "id": "991b169f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# filter the outliers with the interquartile range (IQR) and set up lower/upper bound\n",
        "Q1 = dt_clean['Quantity'].quantile(0.25)\n",
        "Q3 = dt_clean['Quantity'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "filtered_quantities = dt_clean[(dt_clean['Quantity'] >= lower_bound) & (dt_clean['Quantity'] <= upper_bound)]['Quantity']\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(filtered_quantities, bins=50, kde=False)\n",
        "plt.title('Distribution of Quantity within IQR')\n",
        "plt.xlabel('Quantity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# statistics for the filtered Quantity data\n",
        "filtered_quantity_description = filtered_quantities.describe()\n",
        "print(\"Quantity Data: \", filtered_quantity_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f87597",
      "metadata": {
        "id": "68f87597"
      },
      "source": [
        "### Visual Analytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Violin Plot for Quantity by Country"
      ],
      "metadata": {
        "id": "9SZIFkRpkxA3"
      },
      "id": "9SZIFkRpkxA3"
    },
    {
      "cell_type": "markdown",
      "id": "6492b905",
      "metadata": {
        "id": "6492b905"
      },
      "source": [
        "The violin plot above illustrates the distribution of quantities ordered by customers by country.\n",
        "This is particularly useful for identifying trends in purchasing behavior across different markets, visualizing the distribution density along with the range of the data.\n",
        "\n",
        "< Interpretation >\n",
        "*   The bulk of orders are centered around a quantity of zero, which may indicate a high volume of small-quantity transactions across all countries.\n",
        "*   The length of the violins indicates the range of order quantities, while the width shows the frequency. Wider sections represent a higher frequency of orders at that quantity level, indicating common order sizes.\n",
        "*   Several countries with extreme negative quantities - returns or canceled orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cc84a2",
      "metadata": {
        "id": "62cc84a2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.violinplot(x='Country', y='Quantity', data=dt_clean[dt_clean['Quantity'] < 50])  # Limiting to reasonable quantities\n",
        "plt.title('Quantity Distribution by Country')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f18464eb",
      "metadata": {
        "id": "f18464eb"
      },
      "source": [
        "#### Faceted Grid Plot for Quantity and Price"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4e55586",
      "metadata": {
        "id": "c4e55586"
      },
      "source": [
        "The collection of plots allows for a comparative analysis of sales by country, highlighting areas of success, challenges, and growth opportunities.\n",
        "\n",
        "Key Findings:\n",
        "\n",
        "* United Kingdom: Primary market, high volume of transactions, mostly small quantities.\n",
        "* France and Germany: Fewer transactions, wider range of quantities, smaller but more variable markets.\n",
        "* Nigeria and Malta: Very few transactions, higher-quantity sales potentially indicate bulk purchases.\n",
        "\n",
        "* Negative Quantities: Returns or cancelled orders, significant in some countries like Iceland and West Indies, may skew average quantity figures.\n",
        "* Distribution of Sales: Informs marketing efforts, expansion/reduction decisions, logistics and supply chain strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6566f7",
      "metadata": {
        "scrolled": false,
        "id": "2f6566f7"
      },
      "outputs": [],
      "source": [
        "#Faceted Grid Plot for Quantity and Price\n",
        "grid = sns.FacetGrid(dt_clean, col='Country', col_wrap=4, height=4)\n",
        "grid.map(sns.scatterplot, 'Quantity', 'Price')\n",
        "grid.add_legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "666e0aab",
      "metadata": {
        "id": "666e0aab"
      },
      "source": [
        "## Prediction & Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Linear Regression"
      ],
      "metadata": {
        "id": "M965zKSUnDYT"
      },
      "id": "M965zKSUnDYT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec7f7ba",
      "metadata": {
        "id": "bec7f7ba"
      },
      "outputs": [],
      "source": [
        "# add a column to store the sum of purchase amounts by customer and calc clv\n",
        "dt_clean.insert(1, column = 'TotalSpend', value = dt_clean['Price'] * dt_clean['Quantity'])\n",
        "clv = dt_clean.groupby('Customer ID')['TotalSpend'].sum()\n",
        "\n",
        "\n",
        "# aggregate features by customer\n",
        "X_aggregated = dt_clean.groupby('Customer ID').agg({'Quantity': 'sum', 'Price': 'mean'})\n",
        "y_aggregated = dt_clean.groupby('Customer ID')['TotalSpend'].sum()\n",
        "\n",
        "\n",
        "# make the train and test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_aggregated, y_aggregated, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# train the model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# predict on the test dataset & plot\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.title('Actual vs Predicted CLV - Linear Regression')\n",
        "plt.xlabel('Actual CLV')\n",
        "plt.ylabel('Predicted CLV')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # Diagonal line\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "from sklearn.metrics import root_mean_squared_error, r2_score\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "rmse = root_mean_squared_error(y_test, y_pred)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f'R-squared: {r_squared}')"
      ],
      "metadata": {
        "id": "Tmn0li13rfDx"
      },
      "id": "Tmn0li13rfDx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fd13293f",
      "metadata": {
        "id": "fd13293f"
      },
      "source": [
        "#### Conclusion\n",
        "RMSE: 3538.44 (Average prediction error of $3,538)\n",
        "\n",
        "R-squared: 0.8656 (Strong model fit, explaining 86.56% of variance)\n",
        "\n",
        "Performance Analysis:\n",
        "* Accurate for lower CLV: Model excels at predicting CLV for customers with lower lifetime value.\n",
        "* Less precise for higher CLV: Model exhibits some variance for customers with exceptionally high CLV, indicating potential for refinement.\n",
        "* Strong model fit: High R-squared suggests that the selected features are influential in predicting CLV.\n",
        "* Overfitting risk: Be mindful of potential overfitting due to the strong R-squared value."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3efa72ea",
      "metadata": {
        "id": "3efa72ea"
      },
      "source": [
        "### 2. Decision Tree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Handle non-linear relationships\n"
      ],
      "metadata": {
        "id": "JRdA86vX08IY"
      },
      "id": "JRdA86vX08IY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd37a34",
      "metadata": {
        "id": "1dd37a34"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import root_mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_aggregated, y_aggregated, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_tree = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# define a grid of parameters to search over\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# use GridSearchCV to find the best parameters & model\n",
        "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_tree = grid_search.best_estimator_\n",
        "\n",
        "# prediction\n",
        "y_pred = best_tree.predict(X_test)\n",
        "\n",
        "plt.scatter(y_test, y_pred, alpha=0.3)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Diagonal line\n",
        "plt.title('Decision Tree Regressor: Actual vs Predicted CLV')\n",
        "plt.xlabel('Actual CLV')\n",
        "plt.ylabel('Predicted CLV')\n",
        "plt.show()\n",
        "\n",
        "# evaluation\n",
        "rmse = root_mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'Best Parameters: {grid_search.best_params_}')\n",
        "print(f'Decision Tree RMSE: {rmse}')\n",
        "print(f'Decision Tree R-squared: {r2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae546d0",
      "metadata": {
        "id": "0ae546d0"
      },
      "source": [
        "#### Conclusion\n",
        "##### Scatter Plot Analysis:\n",
        "* Strong performance for lower CLV: The model accurately predicts CLV for most customers, especially those with lower CLV values.\n",
        "* Increased variance for higher CLV: The model's predictions are less accurate for customers with higher CLV, indicating potential limitations in capturing complex relationships at higher CLV levels.\n",
        "\n",
        "##### Model Performance Metrics:\n",
        "* Lower RMSE: The Decision Tree Regressor has a lower RMSE compared to Linear Regression, indicating better overall prediction accuracy.\n",
        "* Higher R-squared: The Decision Tree Regressor explains a larger portion of the variance in CLV than Linear Regression, suggesting a better fit to the data.\n",
        "\n",
        "##### Best Parameters:\n",
        "* No depth constraint: The model was allowed to grow to its maximum depth, potentially increasing its complexity and risk of overfitting.\n",
        "* Minimal leaf size: The model allowed for very small leaf nodes, providing flexibility but potentially increasing the risk of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79837429",
      "metadata": {
        "id": "79837429"
      },
      "source": [
        "### 3. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* An ensemble of decision trees\n",
        "* Less prone to overfitting\n",
        "* Can capture complex interactions between features"
      ],
      "metadata": {
        "id": "XSPGiy7m0Vn4"
      },
      "id": "XSPGiy7m0Vn4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4138abc9",
      "metadata": {
        "id": "4138abc9"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import root_mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_aggregated, y_aggregated, test_size=0.2, random_state=42)\n",
        "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# model training\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# prediction\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "\n",
        "plt.scatter(y_test, y_pred_rf)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
        "plt.title('Random Forest Regressor: Actual vs Predicted CLV')\n",
        "plt.xlabel('Actual CLV')\n",
        "plt.ylabel('Predicted CLV')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# evaluation\n",
        "rmse_rf = root_mean_squared_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "print(f'Random Forest RMSE: {rmse_rf}')\n",
        "print(f'Random Forest R-squared: {r2_rf}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11239c90",
      "metadata": {
        "id": "11239c90"
      },
      "source": [
        "#### Conclusion\n",
        "##### Scatter Plot Analysis:\n",
        "* Model accurately predicts low CLV values.\n",
        "* Predictions become less accurate for higher CLV values.\n",
        "* Outliers exist where CLV is significantly overestimated.\n",
        "\n",
        "##### Model Performance Metrics:\n",
        "* RMSE: Higher than Linear Regression and Decision Tree, indicating higher prediction error.\n",
        "* R-squared: Slightly lower than previous models, indicating less explained variance in CLV.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5faaf3fd",
      "metadata": {
        "id": "5faaf3fd"
      },
      "source": [
        "### 4. Gradient Boosting\n",
        "Rationale: Gradient boosting is a powerful ensemble method that combines weak predictive models to create a strong predictive model, often leading to high performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d22ea125",
      "metadata": {
        "id": "d22ea125"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import root_mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_aggregated, y_aggregated, test_size=0.2, random_state=42)\n",
        "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gbr.fit(X_train, y_train)\n",
        "y_pred_gbr = gbr.predict(X_test)\n",
        "\n",
        "plt.scatter(y_test, y_pred_gbr)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
        "plt.title('Gradient Boosting Regressor: Actual vs Predicted CLV')\n",
        "plt.xlabel('Actual CLV')\n",
        "plt.ylabel('Predicted CLV')\n",
        "plt.show()\n",
        "\n",
        "rmse_gbr = root_mean_squared_error(y_test, y_pred_gbr)\n",
        "r2_gbr = r2_score(y_test, y_pred_gbr)\n",
        "print(f'Gradient Boosting RMSE: {rmse_gbr}')\n",
        "print(f'Gradient Boosting R-squared: {r2_gbr}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca5e7230",
      "metadata": {
        "id": "ca5e7230"
      },
      "source": [
        "#### Conclusion\n",
        "##### Model Performance:\n",
        "* RMSE: 4014.27, slightly higher than Decision Tree and Random Forest, indicating potential for improvement.\n",
        "* R-squared: 0.8269, strong but lower than previous models, suggesting some variance is not captured.\n",
        "\n",
        "##### Visualization Insights:\n",
        "* Model accuracy: Good for lower CLV values, but decreases for higher CLV values.\n",
        "* Overestimation: Model overestimates CLV for some high-value customers.\n",
        "\n",
        "##### Potential improvements:\n",
        "* Hyperparameter tuning to reduce overfitting.\n",
        "* Additional features or feature engineering for high-value customers.\n",
        "* Handling outliers or customer segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "387855f6",
      "metadata": {
        "id": "387855f6"
      },
      "source": [
        "### 5. Neural Network (Multilayer Perceptron)\n",
        "Rationale: Neural networks can model complex, non-linear patterns that other algorithms may miss. They are especially useful if the relationships in the data are not well captured by traditional algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc0aeac",
      "metadata": {
        "id": "7dc0aeac"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import root_mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_aggregated, y_aggregated, test_size=0.2, random_state=42)\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "plt.scatter(y_test, y_pred_mlp)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
        "plt.title('Neural Network (MLP) Regressor: Actual vs Predicted CLV')\n",
        "plt.xlabel('Actual CLV')\n",
        "plt.ylabel('Predicted CLV')\n",
        "plt.show()\n",
        "\n",
        "rmse_mlp = root_mean_squared_error(y_test, y_pred_mlp)\n",
        "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
        "print(f'Neural Network RMSE: {rmse_mlp}')\n",
        "print(f'Neural Network R-squared: {r2_mlp}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c44a23d6",
      "metadata": {
        "id": "c44a23d6"
      },
      "source": [
        "#### Conclusion\n",
        "* RMSE (3426.86): The model's predictions are on average $3,426.86 off from the actual CLV values, which is a competitive performance compared to other models.\n",
        "* R-squared (0.8739): The model explains 87.39% of the variation in CLV, indicating a strong fit to the data.\n",
        "\n",
        "##### Visualization Analysis:\n",
        "* The model is highly accurate for customers with lower CLV values.\n",
        "* The model may struggle with predicting higher-end CLV values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377c1f2e",
      "metadata": {
        "id": "377c1f2e"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We predicted Customer Lifetime Value (CLV) for an e-commerce customers,applying multiple predictive models:\n",
        "* Linear Regression\n",
        "* Decision Tree\n",
        "* Random Forest\n",
        "* Gradient Boosting\n",
        "* Neural Network (MLP regressor)\n",
        "\n",
        "\n",
        "Based on the performance evaluation via RMSE and R-squared, **Neural Network** generated the most accurate prediction - turned out a powerful predictive model for CLV."
      ],
      "metadata": {
        "id": "HzOJomxN6ZfQ"
      },
      "id": "HzOJomxN6ZfQ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}